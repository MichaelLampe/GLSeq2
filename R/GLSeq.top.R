#########################################################
# Great Lakes Seq package for low-level processing of RNA-Seq data
# Oleg Moskvin; info@scienceforever.com 
# Sept 18, 2013 
#########################################################
# 
# This is the top-level executable script  
#
#########################################################
#
# Usage: Rscript GLSeq.top.R (no)update (no)dataprep (no)alignment (no)counting (no)collect expID AttributeFilePath
#
#########################################################
#
# Starts counting the time
start.time <- proc.time()
#
args <- commandArgs(trailingOnly = TRUE)
#
# update attributes from DB? (otherwise, use values from GLSeg.R as is)
# values: "update", "noupdate" or the name of a particular file with run attributes (GLSeq.attr.XXX.R)
updateFromDb <- as.character(args[1])
#
# prepare data from fastq.gz files? (if not, the split and ready fastq files must be already in the dest.dir)
# values: "dataprep", "nodataprep"
dataPrepare <- as.character(args[2])
#
# Align data?
# values: "alignment", "noalignment" 
alignment <- as.character(args[3])
# 
# Count data?
# values: "nocounting","counting"
counting <- as.character(args[4])
#
# collect results? 
# values: "collect", "nocollect" 
resCollect <- as.character(args[5])
#
# experiment ID
# unique experiment ID used as a key to retrieve atributes from the database for the data processing 
# Text addition to the output files (after library name)
# typically - unique ID of the experiment
# the ID of the run (text.add) generated by the script itself, will be this value concatenated with serial number (01...99) 
expID <- as.character(args[6])
#
# protocol ID
# unique protocol ID used as a key to retrieve atributes from the "protocol" table od the DB 
protID <- as.character(args[7])
#
# full path to the attribute file of this particular run 
# this replaces the original reading of the attribute file from the GLSeq folder (may cause conflicts if more than 1 user want to use GLSeq at the same time)
attrPath <- as.character(args[8])
#
#
# Naturally set to null, if the user would like they can activate
# this log type in the cattribute file by assigning it.
destDirTest <- NULL
#
#
source("GLSeq.Util.R")
#
#
#
# the default run attempt
runAttempt <- formatC(1, width=2, flag="0")
#
# the actual unique run ID - 
# text.add <- paste(expID, runAttempt, sep=".")
# now is being generated here, inside GLSeq.top.R
#
# date of the run
runDate <-  paste(strsplit(date()," ")[[1]], collapse="_")
runDate <- gsub(":", "_", runDate)
#
###################
# Getting input values:
# defaults
###################
#
# Even with "update" selected, attributes are read from the local file first
# to prime the objects in the environment: 
# 'noupdate' leads to using attributes from GLSeq.attr.R 
# 'update' means updatimg from / writing back to a test MySQL database
# 'GLOWNG' results in overwriting attributes from GLSeq.attr.R with new values from GLOW-NG and writing results back to GLOW-NG via web services 
# 
source(attrPath)
#
if (updateFromDb == "noupdate") {
  earlierResults <- dir(base.dir)
  earlierResults <- earlierResults[grep(".rda", earlierResults)]
  earlierResults <- earlierResults[grep(expID, earlierResults)]
  runAttempt <- length(earlierResults) + 1
  runAttempt <- formatC(runAttempt, width=4, flag="0") # Width of 4 was used after a bug was found, 4 should mean no one ever needs to worry about this.
  #
  # the real text.add that will be used as a common ID for all the GLSeq scripts is generated right here:
  text.add <- paste(expID, runAttempt, sep=".") 
}
dest.dir.base <- trailDirCheck(dest.dir.base) # may be redundant; still, fixed an error
# base directory name with guaranteed trailing slash: 
base.dir <- trailDirCheck(base.dir)
#
# Destination directory for the processed files (if no connection to DB performed):
dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
# destination directory name with guaranteed trailing slash: 
dest.dir <- trailDirCheck(dest.dir)
#
# raw directory name with guaranteed trailing slash: 
raw.dir <- trailDirCheck(raw.dir)
# readyData.dir checking
if (!is.null(readyData.dir)) readyData.dir <- trailDirCheck(readyData.dir)
#
###
# the following directories are ALWAYS relative to the base directory!!!
#
# Destination directory for log /stat files:
destDirLog <-  paste(dest.dir, text.add, ".stat/", sep="")
#
#
# Creates a log file
log.file <- NULL
if (!is.null(destDirTest)){
  log.file <- paste(destDirTest,text.add,".RunLog.txt",sep="")
  # Overwrites previous file in case run had problems.
  create.log.file <- paste("echo \"RUN LOG FILE\"",">",log.file)
  add.to.logs("############################################################",log.file)
  try(system(create.log.file))
  add.to.logs(paste("Arguments for this run"),log.file)
}
#
# Handle each case individually in case we end up reworking these more
#
add.to.logs(paste("UPDATE FROM DATABASE:",updateFromDb),log.file)
add.to.logs(paste("PREPARING DATA:",dataPrepare),log.file)
add.to.logs(paste("ALIGNING READS:",alignment),log.file)
add.to.logs(paste("COUNTING ALIGNED READS:",counting),log.file)
add.to.logs(paste("COLLECTING RESULTS:",resCollect),log.file)
add.to.logs(paste("PROTOCOL ID:",protID),log.file)
add.to.logs(paste("ATTRIBUTE FILE LOCATION:",attrPath),log.file)
add.to.logs("################## END OF RUN OPTIONS ##################",log.file)
add.to.logs("################## Selected Attribute File Values ##################",log.file)
add.to.logs(paste("Raw Data Directory:",raw.dir),log.file)
add.to.logs(paste("Ready Data Directory:",readyData.dir),log.file)
add.to.logs(paste("Reference FASTA name:",refFASTAname),log.file)
add.to.logs(paste("Reference GFF name:",refGFFname),log.file)
add.to.logs(paste("Script Directory:",base.dir),log.file)
add.to.logs(paste("Destination Directory:",dest.dir),log.file)
if (aAlgor == "Cushaw") {
  if (GPU.accel){
    add.to.logs("Alignment Algorithm: Cushaw-GPU",log.file)
  }else{
    add.to.logs(paste("Alignment Algorithm:",aAlgor),log.file)
  }
} else{
  add.to.logs(paste("Alignment Algorithm:",aAlgor),log.file)
}
add.to.logs(paste("Counting Algorithm(s):",HTSeq,FeatureCounts,RSEM),log.file)
add.to.logs("################## END OF ATTRIBUTE OPTIONS ##################",log.file)
#
#
if (updateFromDb != "update" & updateFromDb != "noupdate") source(updateFromDb)
#
# generating text.add from local attribute file:
#
# generating text.add for the case of a custom updateFromDb record (including GLOWNG)
# (will not happen anytime soon)
#
#@@@@@@@@@@@@@@@
# Getting input values
# defaults
# End 
#@@@@@@@@@@@@@@@
#
picardToolsPath <- trailDirCheck(picardToolsPath)
##############
# a record of the current run is always saved in the database,
# even if the update from DB is suppressed
if (updateFromDb == "update") {
  require(RMySQL)
  dbcon <- dbConnect(MySQL(), group="glseq")
  #
  # looking for previousely run results with this expID: 
  earlierResults <- dbGetQuery(dbcon, paste("select * from glseqresults where expid = ", "'",expID,"'", sep=""))
  runAttempt <- nrow(earlierResults) + 1
  if (runAttempt < 100) runAttempt <- formatC(runAttempt, width=2, flag="0")
  if (runAttempt >= 100) runAttempt <- formatC(runAttempt, width=3, flag="0") # will probably never happen
  #
  # the real text.add that will be used as a common ID for all the GLSeq scripts is generated right here:
  text.add <- paste(expID, runAttempt, sep=".")
  if (sum(text.add %in% as.character(earlierResults$textadd)) > 0) stop("a record with the current textadd ID - ",  text.add, " - already exists in the database") 
  if (sum("submited" %in% as.character(earlierResults$status)) > 0) warning("a Submitted record for the current experiment ID already exist in the database! \n Please make sure you indeed want to run a parallel computation for this dataset \n ") 
  if (sum("submited" %in% as.character(earlierResults$status)) > 99) stop("at least 99 Submitted records for the current experiment ID already exist in the database! \n Please cleanup the records and check for orphaned computational processes first \n ") 
  #
  # Destination directory for the processed files 
  dest.dir.base <- trailDirCheck(dest.dir.base)
  dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
  #
  # reading attributes from JGI:
  jgiData <- dbGetQuery(dbcon, paste("select * from glseqjgi where expid = ", "'",expID,"'", sep=""))
  Sys.sleep(10)
  # the following .JGI versions of the 4 protocol attributes are used 
  # to check for consistency between requested entires in jgi and protocol tables: 
  strain.JGI <- as.character(jgiData$strain)
  paired.end.JGI <- as.character(jgiData$paired)
  qScores.JGI <- as.character(jgiData$qscores)
  libstrand.JGI <- as.character(jgiData$libstrand)
  # checking is all the libraries associated with the requested runID in JGI table have the same entries 
  # in the 4 fields: 
  if (length(unique(strain.JGI)) > 1) stop("non-unique STRAIN entires for the requested library files in JGI table!") 
  if (length(unique(paired.end.JGI)) > 1) stop("non-unique PAIRED.END entires for the requested library files in JGI table!") 
  if (length(unique(qScores.JGI)) > 1) stop("non-unique QSCORES entires for the requested library files in JGI table!") 
  if (length(unique(libstrand.JGI)) > 1) stop("non-unique LIBSTRAND entires for the requested library files in JGI table!") 
  # keeping 1 value per attribute (in JGI table, those are vectors of attributes):
  strain.JGI <- unique(strain.JGI)
  paired.end.JGI <- unique(paired.end.JGI)
  qScores.JGI <- unique(qScores.JGI)
  libstrand.JGI <- unique(libstrand.JGI)
  #
  # reading protocol-related attributes: 
  protocolData <- dbGetQuery(dbcon, paste("select * from glseqprotocol where protid = ", "'",protID,"'", sep=""))
  Sys.sleep(10)
  # attributes from JGI table: 
  raw.dir <- as.character(jgiData$rawdir) # vector
  libList <-  as.character(jgiData$libfile) # vector
  medium <-  as.character(jgiData$lmedium) # vector
  timepoint <-  as.character(jgiData$timepoint) # vector
  repNum <-  as.character(jgiData$repnum) # vector
  # (strain.JGI, paired.end.JGI, qScores.JGI and libstrand.JGI are already read) 
  # 
  # attributes from protocol table: 
  dest.dir.base <- as.character(protocolData$destdirbase)
  dest.dir.base <- trailDirCheck(dest.dir.base)
  dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
  base.dir <- as.character(protocolData$basedir)
  strain.prot <- as.character(protocolData$strain)
  rGenome <- as.character(protocolData$rgenome)
  paired.end.prot <- as.character(protocolData$paired)
  qScores.prot <- as.character(protocolData$qscores) 
  nCores <- as.numeric(protocolData$ncores)
  nStreams <- as.numeric(protocolData$nstreams) 
  compConf <- as.logical(as.character(protocolData$compconf))
  rawGen <- as.logical(as.character(protocolData$rawgen))
  genobam <- as.logical(as.character(protocolData$genobam)) 
  libstrand.prot <- as.character(protocolData$libstrand)
  strandBase <- as.character(protocolData$strandbase)
  strandExtract <- as.logical(as.character(protocolData$strandextract))  
  libNchar <- as.numeric(protocolData$libnchar) 
  #
  # checking for consistency of records for the 4 attributes in JGI and protocol tables: 
  if (qScores.prot != qScores.JGI) stop("Quality scores format records are different in JGI and protocol tables! \n") 
  if (paired.end.prot != paired.end.JGI) stop("Sequencing type records are different in JGI and protocol tables! \n") 
  if (strain.prot != strain.JGI) stop("Strain name records are different in JGI and protocol tables! \n") 
  if (libstrand.prot != libstrand.JGI) stop("Library strandness records are different in JGI and protocol tables! \n") 
  #
  #############################################################
  # recoding JGI values for the 4 attributes into internal values of GLSeq (acceptable by RSEM etc): 
  #############################################################
  #
  qScores <- NULL
  paired.end <- NULL
  strain <- NULL
  libstrand <- NULL
  # (preliminary wiping out the default values would help in case the subsequent rewriting doesn't happen 
  # and we are silently left with irrelevant default values; we'll have helpful error + stopped computation)
  if (qScores.prot %in% c("phred33", "Phred+33")) qScores <- "phred33" 
  if (qScores.prot %in% c("phred64", "Phred+64")) qScores <- "phred64" 
  if (paired.end.prot %in% c(TRUE, "blablabla")) paired.end <- TRUE # REPLACE WITH REAL JGI value
  if (strain.prot %in% c("MT203pPET", "blablabla")) strain <- "MT203pPET" # REPLACE WITH REAL JGI value
  if (libstrand.prot %in% c("R", "blablabla")) libstrand <- "R" # REPLACE WITH REAL JGI value
  if (libstrand.prot %in% c("F", "blablabla")) libstrand <- "F" # REPLACE WITH REAL JGI value
  #
  ##################
  # recoding of attributes end
  ##################
} # if update from db
#
#@@@@@@@@@@
# Updating input values:
# End
#@@@@@@@@@@
#
# 
#
#
#
#
#
#############
# Directory name checkEnd
#############
#
add.to.logs("################## Creating directories for the run ##################",log.file)
if (alignment == "alignment" || counting == "counting"){
  destDir.create <- paste("mkdir ", dest.dir, sep="")
  destDirLog.create <- paste("mkdir ", destDirLog, sep="")
  add.to.logs(destDir.create,log.file)
  try(system(destDir.create))
  #
  add.to.logs(destDirLog.create,log.file)
  try(system(destDirLog.create))
  #
  if ("HTSeq" %in% cAlgor){
    destDirHTSeqCount <-  paste(dest.dir, text.add, ".HTSeq.Counting/", sep="")
    destDirHTSeqCount.create <- paste("mkdir ", destDirHTSeqCount, sep="")
    #
    add.to.logs(destDirHTSeqCount.create,log.file)
    try(system(destDirHTSeqCount.create))
  }
  #
  if ("FeatureCounts" %in% cAlgor){
    destDirFeatureCountsCount <-  paste(dest.dir, text.add, ".FeatureCounts.Counting/", sep="")
    destDirFeatureCountsCount.create <- paste("mkdir ", destDirFeatureCountsCount, sep="")
    #
    add.to.logs(destDirFeatureCountsCount.create,log.file)
    try(system(destDirFeatureCountsCount.create))
  }
  #
  if ("RSEM" %in% cAlgor){
    destDirRSEMCount <-  paste(dest.dir, text.add, ".RSEM.Counting/", sep="")
    destDirRSEMCount.create <- paste("mkdir ", destDirRSEMCount, sep="")
    #
    add.to.logs(destDirRSEMCount.create,log.file)
    try(system(destDirRSEMCount.create))
  }
  if ("Cufflinks" %in% cAlgor){
    destDirCufflinksCount <-  paste(dest.dir, text.add, ".Cufflinks.Counting/", sep="")
    destDirCufflinksCount.create <- paste("mkdir ", destDirCufflinksCount, sep="")
    #
    add.to.logs(destDirCufflinksCount.create,log.file)
    try(system(destDirCufflinksCount.create))
  }
}
if (resCollect == "collect"){
  if (alignment == "alignment" || counting == "counting"){
    # Collecting on a new run
    collectDir <- paste(dest.dir,text.add,".Collect/",sep="")
    collectDir.create <- paste("mkdir",collectDir)
  } else{
    ### Running an old run again
    previous.dir <- trailDirCheck(previous.dir)
    collectDir <- paste(previous.dir,text.add,".Collect/",sep="")
    collectDir.create <- paste("mkdir",collectDir)
  }
  add.to.logs(collectDir.create,log.file)
  try(system(collectDir.create))
}
#
# Copies the attribute file into the folder.
#
add.to.logs("################## Copying attribute file for this run into destination folder ##################",log.file)
copyAttributeFile <- paste("cp",attrPath,dest.dir)
add.to.logs(copyAttributeFile,log.file)
try(system(copyAttributeFile))
#
###############
# Log-tail command addition
###############
#
runLogFile1 <- paste(destDirLog, text.add, ".runLog1.txt", sep="")
runLogFile2 <- paste(destDirLog, text.add, ".runLog2.txt", sep="")
#
runErrFile1 <- paste(destDirLog, text.add, ".runErr1.txt", sep="")
runErrFile2 <- paste(destDirLog, text.add, ".runErr2.txt", sep="")
#
#
############################
# Preparing data file names (ready for expression computation)
############################
# 
# reusable function for assembly split fastq file names (see below)
fqfiles.table.pe.assemble <- function(fqfiles.base) {
  fqfiles.table <- NULL
  for (i in 1: length(fqfiles.base)) {
    left.fq <- paste(fqfiles.base[i],".1.fq", sep="")
    right.fq <- paste(fqfiles.base[i],".2.fq", sep="")
    fqfiles.table <- rbind(fqfiles.table, c(left.fq, right.fq)) }
  fqfiles.table 
}
#
##########################################################################
########################## NO DATA PREP ##################################
##########################################################################
###########
# A. If the library files are already decompressed and put into 
# the destination directory, i.e. when "nodataprep" is supplied as the second argument
##########
#
if(dataPrepare == "nodataprep") {
  # copying the ready-to-process fastq files to the destination directory:
  if (alignment == "alignment"){
    readyDataCopy <- paste("cp ", readyData.dir, "*.fq ", dest.dir, sep="")
    add.to.logs("################## Copying preprocessed .fq files into destination directory  ##################",log.file)
    add.to.logs(readyDataCopy,log.file)
    system(readyDataCopy)
    #
    Sys.sleep(10)
    if (paired.end) {
      fqfiles <- dir(dest.dir) 
      fqfiles <- fqfiles[grep(".fq", fqfiles)]
      fqfiles.base <- substr(fqfiles, 1,nchar(fqfiles) - 5)
      fqfiles.base <- unique(fqfiles.base)
      # table of pairs of FASTQ file names (1 pair per row):
      # we assemble left and right file names explicitly here because 
      # we don't want to rely on file sequence in the directory and get wrong results if there are occasional unpaired files etc. 
      #
      # assemble function for paired-end libraries:
      fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
    } # if paired-end
    #
    # for single-ended libraries: 
    if (!(paired.end)) {
      fqfiles <- dir(dest.dir) 
      fqfiles <- fqfiles[grep(".fq", fqfiles)]
      fqfiles.table <- cbind(NULL, fqfiles) 
    }
  }
} # if nodataprep
#
##########################################################################
########################## DATA PREP #####################################
##########################################################################
####### 
# If the data needs to be processed all the way
# from the compressed archives in the raw directory
######
#
if(dataPrepare == "dataprep") {
  #
  ##############
  # Paired End
  ##############
  if (paired.end) {
    #
    ########################################
    ############## UPDATE ##################
    ########################################
    # Explicit list of files supplied
    #
    if(updateFromDb == "update") {
      if (is.null(libList)){ 
        error.message.stopping <- "Apparently, no raw file names were retrieved from the database - nothing to work with \n"
        add.to.logs(error.message.stopping,log.file)
        stop(error.message.stopping)
      }
      if(!presplit) fqfiles.base <- substr(libList, 1, nchar(libList)-3)
      if (presplit) fqfiles.base <- substr(libList, 1, nchar(libList)-8)
      fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
    }
    #
    ########################################
    ############ NO UPDATE #################
    ########################################
    # Raw Directory of files supplied 
    #
    if(updateFromDb == "noupdate") {
      gzfiles <- dir(raw.dir)
      fqfiles <- dir(raw.dir)
      if (!unzipped) {
        add.to.logs("################## Finding zipped files to prepare ##################",log.file)
        gzfiles <- gzfiles[grep(".gz", gzfiles)]
        if(!presplit) fqfiles.base <- substr(gzfiles, 1,nchar(gzfiles) - 3)
        if (presplit) fqfiles.base <- substr(gzfiles, 1,nchar(gzfiles) - 8)
        fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
      }
      #
      if (unzipped) {
        add.to.logs("################## Finding unzipped files to prepare ##################",log.file)
        fqfiles <- fqfiles[grep(".fq",fqfiles)]
        if(!presplit) fqfiles.base <- substr(gzfiles, 1,nchar(fqfiles) - 0)
        if (presplit) fqfiles.base <- substr(gzfiles, 1,nchar(fqfiles) - 5)
        fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
      }
    }
  }
  #
  ##############
  # Single End
  ##############
  if (!(paired.end))  {
    gzfiles <- dir(raw.dir)
    fqfiles <- dir(raw.dir)
    if (!unzipped){
      add.to.logs("################## Finding zipped files to prepare ##################",log.file)
      gzfiles <- dir(raw.dir) 
      gzfiles <- gzfiles[grep(".gz", gzfiles)] # just in case raw.dir has somethig else besides .gz files
      fqfiles <- substr(gzfiles, 1, nchar(gzfiles)-3)
      fqfiles.table <- cbind(NULL, fqfiles)
    }
    if (unzipped){
      add.to.logs("################## Finding unzipped files to prepare ##################",log.file)
      fqfiles <- dir(raw.dir) 
      fqfiles <- fqfiles[grep(".fq", fqfiles)] # just in case raw.dir has somethig else besides .fq files
      fqfiles <- substr(gzfiles, 1, nchar(fqfiles)-0)
      fqfiles.table <- cbind(NULL, fqfiles)
    }
  }
}
#
##########################################################################
########################## RANGES OF DATA ################################
##########################################################################
#
if (alignment == "alignment"){
  chunk <- function(x, n) split(x, sort(rank(x) %% n)) # commonly known solution to divide data equally
  if (nStreams > nrow(fqfiles.table)) nStreams <- nrow(fqfiles.table) # quiet and nice solution but there will de descrepancy between nStreams in the attribute file and the actual nStreams
  rangelist <- chunk(1:nrow(fqfiles.table), nStreams)
  # ranges are in rangelist[1:nSreams]
  for (ii in 1:nStreams) assign(paste("range",ii,sep=""),rangelist[[ii]])
}
#
##########################################################################
###################### EXPRESSION QUANTIFICATION #########################
##########################################################################
# 
# Some alignments have special case commands which need to be handled
# This will allow for that to be done in the top script
#
# This special case is to facilitate CUSHAW-GPU which processes data
# A bit differently then all the other alignment protocols
GPUspecialCase <- FALSE
# Doesn't run the Alignment if no expresion calculation is desired
this.resName <- NULL
#
if (alignment == "alignment"){
  #
  add.to.logs("################## Creating alignment script ##################",log.file)
  source("GLSeq.Alignment.R")
  #
} else{
  if(counting == "counting"){
    add.to.logs(paste("Starting counting:", fqfiles.table),log.file)
    #
    comm.stack.pool <- "date"
    #
    countable.sams <- dir(countable.sams.dir)[grep("countable.sam", dir(countable.sams.dir))]
    #
    for (i in 1:length(countable.sams)){
      countable.sam <- countable.sams[i]
      copy.comm <- paste("cp",paste(countable.sams.dir,countable.sam,sep="/"),dest.dir)
      #
      add.to.logs("################## Copying premade SAM files into directory ##################",log.file)
      add.to.logs(copy.comm,log.file)
      #
      system(copy.comm)
      setwd(base.dir)
      source("GLSeq.Counting.R")
    }
    comm.stack.pool <- paste(comm.stack.pool,"&&",count.comm,"&")
  }
}
#
if (counting == "counting"){
  if ("RSEM" %in% cAlgor){
    comm.stack.pool <- paste(comm.stack.pool,"wait")
    comm.stack.pool <- paste(comm.stack.pool,"&&","cd",dest.dir,"&&","mv",paste("*.RSEM.counts.*"),destDirRSEMCount)
    comm.stack.pool <- paste(comm.stack.pool,"&&","mv","*.index.*",destDirRSEMCount)
  }
}
#
###########################################################################
###################### Final File Move ####################################
###########################################################################
#
#final.file.move <- paste("cd",dest.dir.base,"mv",paste("AttributeConfig",expID,"*",sep=""),dest.dir,"mv",paste("RunConfig",expID,"*",sep=""),dest.dir)
#comm.stack.pool <- comm.stack.pool <- paste(comm.stack.pool,"&&",final.file.move)
##########################################################################
####################### SAVE RUN VARIABLES ###############################
##########################################################################
setwd(base.dir)
currentRun.dataFile <- paste("GLSeq.vars.", text.add, ".rda", sep="")
if (currentRun.dataFile %in% dir(base.dir)) {
  cat(timestamp(), " Attribute file for this run ID - ", " \n", currentRun.dataFile, " - is already saved; keeping the original file ", "\n")
  currentRun.dataFile.base <- substr(currentRun.dataFile, 1, nchar(currentRun.dataFile) -4)
  add.num <- 1 }
# saving a version of the attribute file with numeric addon:nStreams
while(currentRun.dataFile %in% dir(base.dir)) {
  currentRun.dataFile <- paste(currentRun.dataFile.base, add.num, "rda", sep=".")
  add.num <- add.num+1 
}
if (!(currentRun.dataFile %in% dir(base.dir))) save.image(file=currentRun.dataFile)
#
##################
# Save record of run in the results
# section of the database
#################
if (updateFromDb == "update") {
  glseqresults <- as.data.frame(cbind(expid=expID, protid=protID, rundate=runDate, runend=NULL, textadd=text.add, destdir=dest.dir, destdirbam=destDirBam, destdircount=destDirCount, destdirlog=destDirLog, status="Submitted")) 
  dbWriteTable(dbcon, "glseqresults", glseqresults, row.names = FALSE, append=TRUE)
  Sys.sleep(10)
  dbDisconnect(dbcon) 
}
#
##########################################################################
####################### PREPARE DATA #####################################
##########################################################################
if (dataPrepare  == "dataprep") {
  Sys.sleep(10) 
  dataPrepLog <- paste(destDirLog, text.add, ".DataPrepLog.txt", sep="")
  dataPrepErr <- paste(destDirLog, text.add, ".DataPrepErr.txt", sep="")
  dataPrep <- paste("Rscript GLSeq.dataprep.R ", text.add, " 1>> ", dataPrepLog, " 2>> ", dataPrepErr, sep="") 
  print("Starting Data Preparation")
  system(dataPrep)
}
#
#################
# Watch for readiness of the data files 
# before starting the expression calculations
################
DataIsWaiting <- TRUE
if (dataPrepare == "dataprep"){
  setwd(dest.dir)
  DataIsWaiting <- FALSE 
}
dataReady.ind <- paste(text.add, ".DataReady", sep="") 
# 
# Waiting
#
while(!(DataIsWaiting)) {
  Sys.sleep(21)
  DataIsWaiting <- dataReady.ind %in% dir(dest.dir)
}
if (dataPrepare == "dataprep"){
  if (DataIsWaiting) print("Data Preparation Complete")
}
#
##########################################################################
#################### EXPRESSION CALCULATION ##############################
##########################################################################
if (DataIsWaiting) {
  Sys.sleep(10) 
  #
  # Base case
  if (GPUspecialCase) 
  {
    if (dataPrepare == "dataprep")
    {
      add.to.logs("################## Alignment with CUSHAW-GPU starting ##################",log.file)
      add.to.logs(Cushawgpu.special.case,log.file)
      cushaw.start.time <- proc.time()
      system(Cushawgpu.special.case)
      #
      add.to.logs(paste("Cushaw alignment took", proc.time()[3] - cushaw.start.time[3],"seconds to complete"),log.file)
      #
      warning("The alignment step has now completed.")
    }
  }
  print("Starting command")
  add.to.logs("################## Executing communication script ##################",log.file)
  add.to.logs(comm.stack.pool,log.file)
  stack.start.time <- proc.time()
  t <- try(system(comm.stack.pool))
  #
  add.to.logs(paste("Alignment and/or counting stack took",proc.time()[3] - stack.start.time[3],"seconds to complete"),log.file)
  #
  if (t == 0){
    add.to.logs("Communication script executed successfully.",log.file)
    print("Successfully executed command")
  } else{
    add.to.logs("Communication script exited with a failure message.",log.file)
  }
}
#
###########################################################################
###################### COLLECT ############################################
###########################################################################
#
if (resCollect == "collect" && alignment == "noalignment" && counting == "nocounting"){
  dest.dir <- previous.dir
  dest.dir <- trailDirCheck(dest.dir)
  destDirFeatureCountsCount <-  paste(dest.dir,previous.run.name,".FeatureCounts.counting/", sep="")
  destDirHTSeqCount <-  paste(dest.dir,previous.run.name,".HTSeq.counting/", sep="")
  destDirRSEMCount <-  paste(dest.dir,previous.run.name,".RSEM.counting/", sep="")
}
if (resCollect == "collect" && counting == "counting"){
  setwd(base.dir)
  add.to.logs("################## Starting Results Collection ##################",log.file)
  print("STARTED COLLECTION")
  source("GLSeq.ResultsCollect.R")
}
# Summarize it all.
#print("STARTED SUMMARY")
#setwd(base.dir)
#source("GLSeq.runSummary.R")
add.to.logs(paste("The process took:",(proc.time()[3]-start.time[3]),"seconds to complete."),log.file)
stop("Program complete.")